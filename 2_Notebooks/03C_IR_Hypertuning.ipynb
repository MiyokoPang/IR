{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4c2cc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n",
      "Results will be saved to: c:\\Users\\18kyu\\Desktop\\Unishit\\IR\\4_Results\\Tuning_Runs\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports & Configuration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Database\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "\n",
    "# Metrics and Preprocessing\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Hypertuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"Libraries imported.\")\n",
    "\n",
    "# Database Configuration\n",
    "db_config = {\n",
    "    'host': '127.0.0.1',\n",
    "    'user': 'root',\n",
    "    'password': '',  \n",
    "    'database': 'trading_system'\n",
    "}\n",
    "db_url = f\"mysql+pymysql://{db_config['user']}:{db_config['password']}@{db_config['host']}/{db_config['database']}\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# Path Definition\n",
    "base_dir = Path.cwd().parent\n",
    "output_dir = base_dir / \"4_Results\" / \"Tuning_Runs\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Results will be saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3248402b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 'model_features' table from database.\n",
      "Successfully loaded 1,855,010 rows.\n",
      "Data date range: 2010-04-11 to 2020-05-31\n",
      "Number of unique tickers: 4028\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load 'model_features' table from database\n",
    "print(\"Loading 'model_features' table from database.\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_sql(\"SELECT * FROM model_features\", con=engine)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values(by=['ticker', 'date'])\n",
    "    \n",
    "    print(f\"Successfully loaded {len(df):,} rows.\")\n",
    "    print(f\"Data date range: {df['date'].min().date()} to {df['date'].max().date()}\")\n",
    "    print(f\"Number of unique tickers: {df['ticker'].nunique()}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR loading data: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4438de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Defining feature sets for model training.\n",
      "Total feature sets: 3\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Define Feature Sets\n",
    "print(\"\\n Defining feature sets for model training.\")\n",
    "\n",
    "# 1. Price_Only\n",
    "price_features = [\n",
    "    'prev_close', 'ma_3', 'ma_5', 'ma_10', 'volatility',\n",
    "    'rsi', 'momentum_3', 'momentum_5', 'volume'\n",
    "]\n",
    "\n",
    "# 2. Price_Base_Sentiment\n",
    "base_sentiment_features = price_features + [\n",
    "    'textblob_polarity', 'vader_compound', 'finbert_compound'\n",
    "]\n",
    "\n",
    "# 3. Price_Full_Sentiment\n",
    "full_sentiment_features = price_features + [\n",
    "    'textblob_polarity', 'vader_compound', 'finbert_compound',\n",
    "    'news_count', 'has_news', 'days_since_news', 'sentiment_freshness',\n",
    "    'textblob_polarity_volatility', 'vader_compound_volatility',\n",
    "    'finbert_compound_volatility', 'finbert_momentum_3',\n",
    "    'vader_momentum_3', 'textblob_momentum_3'\n",
    "]\n",
    "\n",
    "# Store feature sets\n",
    "feature_sets = {\n",
    "    \"Price_Only\": price_features,\n",
    "    \"Price_Base_Sentiment\": base_sentiment_features,\n",
    "    \"Price_Full_Sentiment\": full_sentiment_features\n",
    "}\n",
    "\n",
    "print(f\"Total feature sets: {len(feature_sets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a11c680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining models and hyperparameter search spaces.\n",
      "Configured 6 model families for tuning.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Define Models & Parameter Grids for Tuning\n",
    "print(\"Defining models and hyperparameter search spaces.\")\n",
    "\n",
    "# 1. Ridge\n",
    "grid_ridge = {\n",
    "    'alpha': uniform(0.1, 10.0)  # Sample from 0.1 to 10.0\n",
    "}\n",
    "\n",
    "# 2. Lasso\n",
    "grid_lasso = {\n",
    "    'alpha': uniform(0.001, 1.0) # Sample from 0.001 to 1.0\n",
    "}\n",
    "\n",
    "# 3. SVR\n",
    "grid_svr = {\n",
    "    'C': uniform(0.1, 10.0),\n",
    "    'gamma': ['scale', 'auto'] + list(uniform(0.001, 0.1).rvs(3)),\n",
    "    'kernel': ['rbf'] # Stick with RBF as it's most common\n",
    "}\n",
    "\n",
    "# 4. Random Forest\n",
    "grid_rf = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': [None] + list(randint(5, 20).rvs(3)),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['auto', 'sqrt', 1.0]\n",
    "}\n",
    "\n",
    "# 5. XGBoost\n",
    "grid_xgb = {\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'subsample': uniform(0.7, 0.3), # 0.7 to 1.0\n",
    "    'colsample_bytree': uniform(0.7, 0.3)\n",
    "}\n",
    "\n",
    "# 6. MLP Regressor\n",
    "grid_mlp = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (64, 32), (50, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': uniform(0.0001, 0.01),\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "models_to_tune = {\n",
    "    \"Ridge\": (Ridge(random_state=42), grid_ridge),\n",
    "    \"Lasso\": (Lasso(random_state=42), grid_lasso),\n",
    "    \"SVR\": (SVR(), grid_svr),\n",
    "    \"RandomForest\": (RandomForestRegressor(random_state=42), grid_rf),\n",
    "    \"XGBoost\": (xgb.XGBRegressor(objective='reg:squarederror', random_state=42), grid_xgb),\n",
    "    \"MLP\": (MLPRegressor(random_state=42, max_iter=500, early_stopping=True), grid_mlp)\n",
    "}\n",
    "\n",
    "print(f\"Configured {len(models_to_tune)} model families for tuning.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3fffdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Define Helper Functions\n",
    "def calculate_metrics(y_true, y_pred, model_name, ticker, feature_set_name):\n",
    "    \"\"\"Calculate metrics with safety checks\"\"\"\n",
    "    mask = ~(np.isnan(y_true) | np.isnan(y_pred) | np.isinf(y_true) | np.isinf(y_pred))\n",
    "    y_true_clean = y_true[mask]\n",
    "    y_pred_clean = y_pred[mask]\n",
    "    \n",
    "    if len(y_true_clean) == 0:\n",
    "        return None\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_true_clean, y_pred_clean))\n",
    "    mae = mean_absolute_error(y_true_clean, y_pred_clean)\n",
    "    r2 = r2_score(y_true_clean, y_pred_clean)\n",
    "    correct_direction = np.sign(y_true_clean) == np.sign(y_pred_clean)\n",
    "    directional_accuracy = np.mean(correct_direction) * 100\n",
    "    \n",
    "    return {\n",
    "        'ticker': ticker,\n",
    "        'model': model_name,\n",
    "        'feature_set': feature_set_name,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'directional_accuracy': directional_accuracy\n",
    "    }\n",
    "\n",
    "print(\"Helper functions defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ef3dddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Model Hypertuning Loop.\n",
      "Will tune models for 10 tickers.\n",
      "Using RandomizedSearchCV with n_iter=10 and cv=3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab2c449f0b745ecab6cfca1435134ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Tickers:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Hypertuning Complete. Total results generated: 160.\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Main Tuning Loop\n",
    "\n",
    "print(\"Starting Model Hypertuning Loop.\")\n",
    "\n",
    "all_results = []\n",
    "top_10_tickers = df['ticker'].value_counts().head(10).index.tolist()\n",
    "\n",
    "N_ITER = 10  # Number of parameter combinations to try. Increase for more thoroughness.\n",
    "CV_FOLDS = 3 # Number of cross-validation folds.\n",
    "\n",
    "print(f\"Will tune models for {len(top_10_tickers)} tickers.\")\n",
    "print(f\"Using RandomizedSearchCV with n_iter={N_ITER} and cv={CV_FOLDS}.\")\n",
    "\n",
    "for ticker in tqdm(top_10_tickers, desc=\"Processing Tickers\"):\n",
    "    ticker_df = df[df['ticker'] == ticker]\n",
    "    \n",
    "    # 1. Split data\n",
    "    split_idx = int(len(ticker_df) * 0.8)\n",
    "    train_df = ticker_df.iloc[:split_idx]\n",
    "    test_df = ticker_df.iloc[split_idx:]\n",
    "    \n",
    "    if len(train_df) < 50 or len(test_df) < 5:\n",
    "        continue\n",
    "        \n",
    "    # 2. Iterate through feature sets\n",
    "    for set_name, feature_cols in feature_sets.items():\n",
    "        \n",
    "        # 3. Scale data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(train_df[feature_cols])\n",
    "        X_test = scaler.transform(test_df[feature_cols])\n",
    "        y_train = train_df['target_return'].values\n",
    "        y_test = test_df['target_return'].values\n",
    "\n",
    "        # 4. Iterate through models\n",
    "        for model_name, (model, param_grid) in models_to_tune.items():\n",
    "            \n",
    "            # Skip SVR/MLP for Price_Full_Sentiment (too slow/complex)\n",
    "            if set_name == \"Price_Full_Sentiment\" and model_name in [\"SVR\", \"MLP\"]:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # 5. Run Randomized Search Cross-Validation\n",
    "                search = RandomizedSearchCV(\n",
    "                    estimator=model,\n",
    "                    param_distributions=param_grid,\n",
    "                    n_iter=N_ITER,\n",
    "                    cv=CV_FOLDS,\n",
    "                    scoring='neg_mean_squared_error', # Optimize for RMSE\n",
    "                    n_jobs=-1, # Use all available cores\n",
    "                    random_state=42,\n",
    "                    verbose=0\n",
    "                )\n",
    "                \n",
    "                search.fit(X_train, y_train)\n",
    "                \n",
    "                # 6. Get best model and make predictions\n",
    "                best_model = search.best_estimator_\n",
    "                y_pred = best_model.predict(X_test)\n",
    "                \n",
    "                # 7. Calculate and store metrics\n",
    "                model_full_name = f\"{model_name}_Tuned\"\n",
    "                metrics = calculate_metrics(y_test, y_pred, model_full_name, ticker, set_name)\n",
    "                \n",
    "                if metrics:\n",
    "                    # Add best parameters to the results\n",
    "                    metrics['best_params'] = str(search.best_params_)\n",
    "                    metrics['best_cv_score'] = search.best_score_ # This is neg_mean_squared_error\n",
    "                    all_results.append(metrics)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error tuning {model_name} for {ticker} ({set_name}): {e}\")\n",
    "                continue\n",
    "\n",
    "print(f\"\\n Hypertuning Complete. Total results generated: {len(all_results)}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "728aa0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving tuned model results.\n",
      "Successfully saved 160 results to c:\\Users\\18kyu\\Desktop\\Unishit\\IR\\4_Results\\Tuning_Runs\\03C_Hypertuning_Performance.csv\n",
      "Saving results to 'results_hypertuning' table in database.\n",
      "Successfully wrote results to database!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Save Results\n",
    "print(\"Saving tuned model results.\")\n",
    "\n",
    "if all_results:\n",
    "    # 1. Convert to DataFrame\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    results_df['timestamp'] = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # 2. Save to CSV\n",
    "    csv_path = output_dir / \"03C_Hypertuning_Performance.csv\"\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Successfully saved {len(results_df)} results to {csv_path}\")\n",
    "    \n",
    "    # 3. Save to Database\n",
    "    print(\"Saving results to 'results_hypertuning' table in database.\")\n",
    "    try:\n",
    "        results_df.to_sql(\n",
    "            'results_hypertuning',\n",
    "            con=engine,\n",
    "            if_exists='replace',\n",
    "            index=False,\n",
    "            chunksize=1000\n",
    "        )\n",
    "        print(\"Successfully wrote results to database!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing results to database: {e}\")\n",
    "else:\n",
    "    print(\"No results were generated. Skipping save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffd7aa1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hypertuning Performance Summary ---\n",
      "\n",
      " Average Performance of Tuned Models:\n",
      "                                         avg_rmse  avg_r2  avg_dir_acc  count\n",
      "model              feature_set                                               \n",
      "Lasso_Tuned        Price_Base_Sentiment    0.0715 -0.0057      52.8302     10\n",
      "                   Price_Full_Sentiment    0.0715 -0.0057      52.8302     10\n",
      "                   Price_Only              0.0715 -0.0057      52.8302     10\n",
      "XGBoost_Tuned      Price_Full_Sentiment    0.0719 -0.0264      51.3208     10\n",
      "                   Price_Base_Sentiment    0.0719 -0.0260      49.9057     10\n",
      "                   Price_Only              0.0720 -0.0282      51.6981     10\n",
      "RandomForest_Tuned Price_Full_Sentiment    0.0721 -0.0320      50.6604     10\n",
      "Ridge_Tuned        Price_Only              0.0727 -0.0418      51.0377     10\n",
      "RandomForest_Tuned Price_Base_Sentiment    0.0728 -0.0533      49.9057     10\n",
      "Ridge_Tuned        Price_Base_Sentiment    0.0733 -0.0572      53.3962     10\n",
      "RandomForest_Tuned Price_Only              0.0739 -0.1067      48.5849     10\n",
      "SVR_Tuned          Price_Base_Sentiment    0.0746 -0.1107      47.2642     10\n",
      "Ridge_Tuned        Price_Full_Sentiment    0.0751 -0.1118      50.0000     10\n",
      "SVR_Tuned          Price_Only              0.0754 -0.1308      47.7358     10\n",
      "MLP_Tuned          Price_Only              0.1100 -1.8525      47.5472     10\n",
      "                   Price_Base_Sentiment    0.1454 -4.3916      47.7358     10\n",
      "\n",
      " Best Overall Tuned Model (by RMSE):\n",
      "  Ticker: A\n",
      "  Model: Lasso_Tuned\n",
      "  Features: Price_Only\n",
      "  RMSE: 0.037161\n",
      "  R2: -0.001037\n",
      "  Params: {'alpha': np.float64(0.3755401188473625)}\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Summary of Best Models\n",
    "print(\"\\n--- Hypertuning Performance Summary ---\")\n",
    "\n",
    "if all_results:\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Show mean performance by model type\n",
    "    summary = results_df.groupby(['model', 'feature_set']).agg(\n",
    "        avg_rmse=('rmse', 'mean'),\n",
    "        avg_r2=('r2', 'mean'),\n",
    "        avg_dir_acc=('directional_accuracy', 'mean'),\n",
    "        count=('ticker', 'count')\n",
    "    ).sort_values(by='avg_rmse').round(4)\n",
    "    \n",
    "    print(\"\\n Average Performance of Tuned Models:\")\n",
    "    print(summary.to_string())\n",
    "\n",
    "    # Show the single best model overall\n",
    "    best_overall = results_df.loc[results_df['rmse'].idxmin()]\n",
    "    print(\"\\n Best Overall Tuned Model (by RMSE):\")\n",
    "    print(f\"  Ticker: {best_overall['ticker']}\")\n",
    "    print(f\"  Model: {best_overall['model']}\")\n",
    "    print(f\"  Features: {best_overall['feature_set']}\")\n",
    "    print(f\"  RMSE: {best_overall['rmse']:.6f}\")\n",
    "    print(f\"  R2: {best_overall['r2']:.6f}\")\n",
    "    print(f\"  Params: {best_overall['best_params']}\")\n",
    "else:\n",
    "    print(\"No results to summarize.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
